{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.autograd import Variable\n",
    "from torchvision.utils import save_image\n",
    "\n",
    "from mlp_models import VAE, CBM, OSR_VAE\n",
    "from test_functions import *\n",
    "\n",
    "import os\n",
    "\n",
    "## LOAD VAE AND CBM\n",
    "path = '../mnist_data/only_4_5/'\n",
    "\n",
    "## INITIALIZATION\n",
    "bs = 100\n",
    "transform = transforms.ToTensor()\n",
    "train_dataset = datasets.MNIST(root='../mnist_data', train=True, transform=transform, download=True)\n",
    "#train_dataset, val_dataset = torch.utils.data.random_split(dataset, [40000, 20000])\n",
    "\n",
    "test_dataset = datasets.MNIST(root='../mnist_data', train=False, transform=transforms.ToTensor(), download=True)\n",
    "\n",
    "# Data Loader (Input Pipeline)\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, batch_size=bs, shuffle=True)\n",
    "val_loader = train_loader #torch.utils.data.DataLoader(dataset=val_dataset, batch_size=bs, shuffle=True)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_dataset, batch_size=bs, shuffle=False)\n",
    "\n",
    "\n",
    "cbm = torch.load(path+'cbm.pt', map_location=torch.device('cpu'))\n",
    "vae = torch.load(path+'vae.pt', map_location=torch.device('cpu'))\n",
    "osr_vae = torch.load(path+'osr_vae_big.pt', map_location=torch.device('cpu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "\n",
    "def log_regression(values, y, test_x, test_y, name='VAE'):\n",
    "    z = torch.sigmoid(values)[:,:2].detach().numpy()\n",
    "    y = y.detach().numpy().ravel()\n",
    "    y = np.array(y%2==0, dtype=int)\n",
    "    test_x = torch.sigmoid(test_x)[:,:2].detach().numpy()\n",
    "    test_y = test_y.detach().numpy().ravel()\n",
    "    test_y = np.array(test_y%2==0, dtype=int)\n",
    "    \n",
    "    print(len(z))\n",
    "    \n",
    "    log_reg = LogisticRegression(max_iter=1000)\n",
    "    log_reg.fit(z,y)\n",
    "    print(name+' Score:', log_reg.score(test_x,test_y)*100)\n",
    "    print('Coeff:', log_reg.coef_)\n",
    "    return log_reg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# LAOD DATASET\n",
    "\n",
    "values_cbm  = torch.zeros(len(train_dataset), 2)\n",
    "values_vae  = torch.zeros(len(train_dataset), 2)\n",
    "values_osr_vae  = torch.zeros(len(train_dataset), 2)\n",
    "\n",
    "targets = torch.zeros(len(train_dataset), 1)\n",
    "final_mask = torch.zeros(len(train_dataset), dtype=torch.bool)\n",
    "j = 0\n",
    "\n",
    "bs = train_loader.batch_size\n",
    "for data in train_loader:\n",
    "    x, y = data\n",
    "    mask = torch.tensor( (y != 4) & (y != 5), dtype=torch.bool)\n",
    "    mu_cbm = cbm(x)\n",
    "    recon, mu, log_var, z_vae = vae(x)\n",
    "    recon, mu, log_var, z_osr = osr_vae(x)\n",
    "    \n",
    "    values_cbm[j*bs:(j+1)*bs] = mu_cbm[:,:2]\n",
    "    values_vae[j*bs:(j+1)*bs] = z_vae[:,:2]\n",
    "    values_osr_vae[j*bs:(j+1)*bs] = z_osr[:,:2]\n",
    "    targets[j*bs:(j+1)*bs] = y.view(-1,1)\n",
    "    final_mask[j*bs:(j+1)*bs] = mask\n",
    "    j += 1\n",
    "\n",
    "values_cbm = values_cbm[final_mask]\n",
    "values_vae = values_vae[final_mask]\n",
    "values_osr_vae = values_osr_vae[final_mask]\n",
    "targets = targets[final_mask]\n",
    "\n",
    "#########################################################################\n",
    "\n",
    "test_values_cbm  = torch.zeros(len(test_dataset), 2)\n",
    "test_values_vae  = torch.zeros(len(test_dataset), 2)\n",
    "test_values_osr_vae  = torch.zeros(len(test_dataset), 2)\n",
    "\n",
    "test_targets = torch.zeros(len(test_dataset), 1)\n",
    "test_final_mask = torch.zeros(len(test_dataset), dtype=torch.bool)\n",
    "j = 0\n",
    "bs = test_loader.batch_size\n",
    "for data in test_loader:\n",
    "    x, y = data\n",
    "    mask = torch.tensor( (y != 4) & (y != 5), dtype=torch.bool)\n",
    "    mu_cbm = cbm(x)\n",
    "    _, _, _, z_vae = vae(x)\n",
    "    _, _, _, z_osr = osr_vae(x)\n",
    "\n",
    "    test_values_cbm[j*bs:(j+1)*bs] = mu_cbm[:,:2]\n",
    "    test_values_vae[j*bs:(j+1)*bs] = z_vae[:,:2]\n",
    "    test_values_osr_vae[j*bs:(j+1)*bs] = z_osr[:,:2]\n",
    "    test_targets[j*bs:(j+1)*bs] = y.view(-1,1)\n",
    "    test_final_mask[j*bs:(j+1)*bs] = mask\n",
    "    j += 1\n",
    "test_values_cbm = test_values_cbm[test_final_mask]\n",
    "test_values_vae = test_values_vae[test_final_mask]\n",
    "test_values_osr_vae = test_values_osr_vae[test_final_mask]\n",
    "test_targets = test_targets[test_final_mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# representation of 4 and 5 in the latent space\n",
    "\n",
    "train_values_cbm  = torch.zeros(len(train_dataset), 2)\n",
    "train_values_vae  = torch.zeros(len(train_dataset), 2)\n",
    "train_values_osr  = torch.zeros(len(train_dataset), 2)\n",
    "\n",
    "train_targets = torch.zeros(len(train_dataset), 1)\n",
    "train_mask = torch.zeros(len(train_dataset), dtype=torch.bool)\n",
    "j = 0\n",
    "\n",
    "bs = train_loader.batch_size\n",
    "for data in train_loader:\n",
    "    x, y = data\n",
    "    mask = torch.tensor( (y == 4) | (y == 5), dtype=torch.bool)        \n",
    "    \n",
    "    mu_cbm = cbm(x)\n",
    "    recon, mu, log_var, z_vae = vae(x)\n",
    "    recon, mu, log_var, z_osr = osr_vae(x)\n",
    "\n",
    "    train_values_cbm[j*bs:(j+1)*bs] = mu_cbm[:,:2]        \n",
    "    train_values_vae[j*bs:(j+1)*bs] = z_vae[:,:2]\n",
    "    train_values_osr[j*bs:(j+1)*bs] = z_osr[:,:2]\n",
    "\n",
    "    train_targets[j*bs:(j+1)*bs] = y.view(-1,1)\n",
    "    train_mask[j*bs:(j+1)*bs] = mask\n",
    "    j += 1\n",
    "train_values_cbm = train_values_cbm[train_mask]\n",
    "train_values_vae = train_values_vae[train_mask]\n",
    "train_values_osr = train_values_osr[train_mask]\n",
    "train_targets = train_targets[train_mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### OPENSET MECHANISM - DIFFIDENT ####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.integrate as integrate\n",
    "from scipy.stats import norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y4 = torch.tensor([1,0], dtype=torch.float) \n",
    "y5 = torch.tensor([0,1], dtype=torch.float) \n",
    "mu4 = osr_vae.z_enc(y4).detach().numpy()\n",
    "mu5 = osr_vae.z_enc(y5).detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## CREATE Z in 4 and 5\n",
    "values_osr_vae  = torch.zeros(len(train_dataset), 2)\n",
    "\n",
    "targets = torch.zeros(len(train_dataset), 1)\n",
    "rec_error =torch.tensor(0.)\n",
    "final_mask = torch.zeros(len(train_dataset), dtype=torch.bool)\n",
    "j = 0\n",
    "\n",
    "bs = train_loader.batch_size\n",
    "rec_errors = torch.zeros(len(train_dataset))\n",
    "print(rec_errors.size())\n",
    "for data in (train_loader):\n",
    "    x, y = data\n",
    "    mask = torch.tensor( (y == 4) | (y == 5), dtype=torch.bool)\n",
    "    recon, mu, log_var, z = osr_vae(x)\n",
    "    \n",
    "    r = F.binary_cross_entropy(recon, x.view(-1, 784), reduction='mean')\n",
    "    rec_error += r\n",
    "    for k in range(bs):\n",
    "        rec_errors[bs*j+k] = F.binary_cross_entropy(recon[k].view(-1, 784), x[k].view(-1, 784), reduction='mean') \n",
    "    #print(r)\n",
    "    values_osr_vae[j*bs:(j+1)*bs] = z[:,:2]\n",
    "    targets[j*bs:(j+1)*bs] = y.view(-1,1)\n",
    "    final_mask[j*bs:(j+1)*bs] = mask\n",
    "    j += 1\n",
    "    \n",
    "values_osr_vae = values_osr_vae[final_mask]\n",
    "targets = targets[final_mask]\n",
    "rec_error /= j\n",
    "\n",
    "rec_thr = rec_error.detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## EVALUATE REC THR\n",
    "\n",
    "recons = rec_errors[final_mask].detach().numpy()\n",
    "l = len(recons)\n",
    "r_min, r_max = np.min(recons), np.max(recons)\n",
    "good_r = []\n",
    "for eta in np.linspace(r_min, r_max, 1000):\n",
    "    mask = (recons < eta)\n",
    "    if len( recons[mask] )/l > 0.94 and len( recons[mask] )/l < 0.96:\n",
    "        good_r.append(eta)\n",
    "rec_thr = np.mean(good_r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## CALCULATE PROB OF INTEGRALs\n",
    "import scipy\n",
    "from scipy.stats import norm\n",
    "import scipy.integrate as integrate\n",
    "\n",
    "zs = values_osr_vae.detach().numpy()\n",
    "y = targets.detach().numpy().squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FIND eta_4 and eta_5\n",
    "\n",
    "# ETA 4\n",
    "good_dist = []\n",
    "\n",
    "mask = (y%2 == 0)\n",
    "l = len(zs[mask])\n",
    "\n",
    "print(l)\n",
    "\n",
    "dist = (mu4 - zs[mask])\n",
    "dist = np.array([np.linalg.norm(d) for d in dist ])\n",
    "print(dist)\n",
    "for eta in np.linspace(0, 2, 1000):\n",
    "    \n",
    "    conds = dist < eta \n",
    "    \n",
    "    if conds.sum()/l > 0.94 and  conds.sum()/l < 0.96:\n",
    "        good_dist.append(eta)\n",
    "\n",
    "eta4 = np.mean(good_dist)\n",
    " \n",
    "\n",
    "# ETA 5\n",
    "    \n",
    "good_dist = []\n",
    "\n",
    "mask = (y%2 == 1)\n",
    "l = len(zs[mask])\n",
    "\n",
    "print(l)\n",
    "\n",
    "dist = (mu5 - zs[mask])\n",
    "dist = np.array([np.linalg.norm(d) for d in dist ])\n",
    "print(dist)\n",
    "for eta in np.linspace(0, 2, 1000):\n",
    "    \n",
    "    conds = dist < eta \n",
    "    \n",
    "    if conds.sum()/l > 0.94 and  conds.sum()/l < 0.96:\n",
    "        good_dist.append(eta)\n",
    "\n",
    "eta5 = np.mean(good_dist)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### NOW WE HAVEBOTH THR, let's see on new data what happens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "values_osr_vae  = torch.zeros(len(train_dataset), 2)\n",
    "targets = torch.zeros(len(train_dataset), 1)\n",
    "final_mask = torch.zeros(len(train_dataset), dtype=torch.bool)\n",
    "accepted = torch.zeros(len(train_dataset), dtype=torch.bool)\n",
    "\n",
    "print('Dataset:', len(train_dataset))\n",
    "j = 0\n",
    "\n",
    "bs = train_loader.batch_size\n",
    "for data in train_loader:\n",
    "    x, y = data\n",
    "    mask = torch.tensor( (y != 4) & (y != 5), dtype=torch.bool)\n",
    "    recon, mu, log_var, z = osr_vae(x)\n",
    "    for i in range(len(recon)):\n",
    "        r = F.binary_cross_entropy(recon[i].view(-1, 784), x[i].view(-1, 784), reduction='mean')\n",
    "        #print(r)\n",
    "        if r.item() <= rec_thr:\n",
    "            accepted[j*bs+i] = True\n",
    "        \n",
    "    values_osr_vae[j*bs:(j+1)*bs] = z[:,:2]\n",
    "    targets[j*bs:(j+1)*bs] = y.view(-1,1)\n",
    "    final_mask[j*bs:(j+1)*bs] = mask\n",
    "    j += 1\n",
    "    \n",
    "values_osr_vae = values_osr_vae[final_mask]\n",
    "targets = targets[final_mask]\n",
    "accepted = accepted[final_mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CREATE TRAIN DATASET for LEAKAGE EXP\n",
    "\n",
    "not_4_5_train = pd.DataFrame()\n",
    "not_4_5_train['z1'] = values_osr_vae[:,0].detach().numpy()\n",
    "not_4_5_train['z2'] = values_osr_vae[:,1].detach().numpy()\n",
    "not_4_5_train['targets'] = targets.detach().numpy()\n",
    "not_4_5_train['rec_accepted'] = accepted.detach().numpy()\n",
    "not_4_5_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = np.array(not_4_5_train['rec_accepted'])\n",
    "l = len(not_4_5_train)\n",
    "d = len(targets[mask])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_values_osr_vae  = torch.zeros(len(test_dataset), 2)\n",
    "\n",
    "test_targets = torch.zeros(len(test_dataset), 1)\n",
    "test_final_mask = torch.zeros(len(test_dataset), dtype=torch.bool)\n",
    "accepted = torch.zeros(len(test_dataset), dtype=torch.bool)\n",
    "\n",
    "j = 0\n",
    "bs = test_loader.batch_size\n",
    "for data in test_loader:\n",
    "    x, y = data\n",
    "    mask = torch.tensor( (y != 4) & (y != 5), dtype=torch.bool)\n",
    "    _, _, _, z_osr = osr_vae(x)\n",
    "    \n",
    "    for i in range(len(recon)):\n",
    "        r = F.binary_cross_entropy(recon[i].view(-1, 784), x[i].view(-1, 784), reduction='mean')\n",
    "        #print(r)\n",
    "        if r.item() <= rec_thr:\n",
    "            accepted[j*bs+i] = True\n",
    "    \n",
    "    test_values_osr_vae[j*bs:(j+1)*bs] = z_osr[:,:2]\n",
    "    test_targets[j*bs:(j+1)*bs] = y.view(-1,1)\n",
    "    test_final_mask[j*bs:(j+1)*bs] = mask\n",
    "    j += 1\n",
    "    \n",
    "test_values_osr_vae = test_values_osr_vae[test_final_mask]\n",
    "test_targets = test_targets[test_final_mask]\n",
    "accepted = accepted[test_final_mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CREATE TEST DATASET for LEAKAGE EXP\n",
    "\n",
    "not_4_5_test = pd.DataFrame()\n",
    "not_4_5_test['z1'] = test_values_osr_vae[:,0].detach().numpy()\n",
    "not_4_5_test['z2'] = test_values_osr_vae[:,1].detach().numpy()\n",
    "not_4_5_test['targets'] = test_targets.detach().numpy()\n",
    "not_4_5_test['rec_accepted'] = accepted.detach().numpy()\n",
    "not_4_5_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## see acceptance of train wrt z integral\n",
    "\n",
    "data = np.asarray(not_4_5_train[['z1','z2']])\n",
    "z_accepted = np.zeros(len(data), dtype=bool)\n",
    "#var = np.mean(variances)\n",
    "for i,z in enumerate(data):\n",
    "    \n",
    "    if np.linalg.norm(z - mu4) < eta4:\n",
    "        z_accepted[i] = True\n",
    "    elif np.linalg.norm(z - mu5) < eta5:\n",
    "        z_accepted[i] = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "not_4_5_train['z_accepted'] = z_accepted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.asarray(not_4_5_test[['z1','z2']])\n",
    "z_accepted = np.zeros(len(data), dtype=bool)\n",
    "for i,z in enumerate(data):\n",
    "    if np.linalg.norm(z - mu4) < eta4:\n",
    "        z_accepted[i] = True\n",
    "    elif np.linalg.norm(z - mu5) < eta5:\n",
    "        z_accepted[i] = True\n",
    "\n",
    "not_4_5_test['z_accepted'] = z_accepted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# INTRODUCE THE LOG REGRESSION WITH REJECTION\n",
    "\n",
    "def diffident_log_regression(values, y, test_values, test_y, which_ones, name='VAE'):\n",
    "    z = values\n",
    "    y = np.array(y%2==0, dtype=int)\n",
    "    test_x = test_values\n",
    "    test_y = np.array(test_y%2==0, dtype=int)\n",
    "    \n",
    "    print(len(z))\n",
    "    \n",
    "    log_reg = LogisticRegression(max_iter=1000)\n",
    "    log_reg.fit(z,y)\n",
    "    \n",
    "    accuracy = 0\n",
    "    pred = np.zeros(len(test_x))\n",
    "    for i in range(len(test_x)):\n",
    "        if which_ones[i]:\n",
    "            pred[i] = log_reg.predict(test_values[i].reshape(1,-1))\n",
    "        else:\n",
    "            pred[i] = 0.5\n",
    "            test_x[i] = np.array([0,0])\n",
    "        sort = np.random.binomial(1, pred[i], size=None)\n",
    "        if test_y[i] == sort:\n",
    "            accuracy += 1\n",
    "    \n",
    "    print(name+' Score: with acc', accuracy/len(which_ones))\n",
    "    print('Score with log_reg:', log_reg.score(test_x, test_y) )\n",
    "    print('params', log_reg.coef_)\n",
    "    return log_reg\n",
    "\n",
    "def diffident_prediction(log_reg, zs, which_ones):\n",
    "    preds = []\n",
    "    for i, z in enumerate(zs):\n",
    "        if which_ones[i]:\n",
    "            preds.append(log_reg.predict(z.reshape(1,-1)))\n",
    "        else:\n",
    "            preds.append(np.random.randint(2))\n",
    "    return np.array(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "which_ones = not_4_5_train['rec_accepted'] & not_4_5_train['z_accepted']\n",
    "zs = not_4_5_train[['z1','z2']].values[which_ones]\n",
    "y = not_4_5_train['targets'][which_ones] \n",
    "\n",
    "which_ones = not_4_5_test['rec_accepted'] & not_4_5_test['z_accepted']\n",
    "test_zs = not_4_5_test[['z1','z2']].values\n",
    "test_y = not_4_5_test['targets'] \n",
    "\n",
    "print(len(test_zs), len(test_y))\n",
    "print(len(which_ones))\n",
    "\n",
    "diff_log = diffident_log_regression(zs, y, test_zs, test_y, which_ones, name='OSR_VAE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = diffident_prediction(diff_log, test_zs, which_ones)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
